{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from statistics import mode\n",
    "from typing import Any, Callable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from qiskit import ClassicalRegister, QuantumCircuit, QuantumRegister\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit_aer.primitives import SamplerV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6375433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Classical data handling\n",
    "# ============================================================\n",
    "\n",
    "def load_and_normalize_iris() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    X_petal = X[:, 2:4]  # only petal length and width\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler((0.0, 1.0))\n",
    "    X_norm = scaler.fit_transform(X_petal)\n",
    "    return X_norm, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Encoding helpers\n",
    "# ============================================================\n",
    "\n",
    "def encode_features_to_angles(features: np.ndarray) -> np.ndarray:\n",
    "    f = np.clip(features.astype(float), 0.0, 1.0)\n",
    "    return np.pi * f\n",
    "\n",
    "\n",
    "def apply_angle_encoding(qc: QuantumCircuit, qubits, angles):\n",
    "    for i, a in enumerate(angles):\n",
    "        qc.ry(float(a), qubits[i])\n",
    "\n",
    "\n",
    "def encode_features_to_amplitude_state(features: np.ndarray) -> np.ndarray:\n",
    "    state = None\n",
    "    for x_j in features:\n",
    "        x_j = float(np.clip(x_j, 0.0, 1.0))\n",
    "        v = np.array([np.sqrt(x_j), np.sqrt(1 - x_j)], dtype=np.complex128)\n",
    "        state = v if state is None else np.kron(state, v)\n",
    "\n",
    "    if not Statevector(state).is_valid():\n",
    "        raise ValueError(\"Encoded statevector invalid.\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. SWAP test circuits\n",
    "# ============================================================\n",
    "\n",
    "def build_swap_test_angle(test_angles, train_angles):\n",
    "    n = len(test_angles)\n",
    "\n",
    "    anc = QuantumRegister(1, \"anc\")\n",
    "    qt = QuantumRegister(n, \"test\")\n",
    "    qr = QuantumRegister(n, \"train\")\n",
    "    c = ClassicalRegister(1, \"c\")\n",
    "\n",
    "    qc = QuantumCircuit(anc, qt, qr, c)\n",
    "\n",
    "    apply_angle_encoding(qc, qt, test_angles)\n",
    "    apply_angle_encoding(qc, qr, train_angles)\n",
    "\n",
    "    qc.h(anc[0])\n",
    "    for t, r in zip(qt, qr):\n",
    "        qc.cswap(anc[0], t, r)\n",
    "    qc.h(anc[0])\n",
    "    qc.measure(anc[0], c[0])\n",
    "\n",
    "    return qc\n",
    "\n",
    "\n",
    "def estimate_similarity_angle(test_angles, train_angles, shots, sampler):\n",
    "    qc = build_swap_test_angle(test_angles, train_angles)\n",
    "    out = sampler.run([qc], shots=shots).result()\n",
    "    counts = out[0].data.c.get_counts()\n",
    "    p1 = counts.get(\"1\", 0) / shots\n",
    "    sim = max(0.0, min(1.0, 1 - 2 * p1))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def build_swap_test_amplitude(test_state, train_state):\n",
    "    n = int(np.log2(len(test_state)))\n",
    "\n",
    "    anc = QuantumRegister(1, \"anc\")\n",
    "    qt = QuantumRegister(n, \"test\")\n",
    "    qr = QuantumRegister(n, \"train\")\n",
    "    c = ClassicalRegister(1, \"c\")\n",
    "\n",
    "    qc = QuantumCircuit(anc, qt, qr, c)\n",
    "    qc.initialize(test_state, qt)\n",
    "    qc.initialize(train_state, qr)\n",
    "\n",
    "    qc.h(anc[0])\n",
    "    for t, r in zip(qt, qr):\n",
    "        qc.cswap(anc[0], t, r)\n",
    "    qc.h(anc[0])\n",
    "    qc.measure(anc[0], c[0])\n",
    "\n",
    "    return qc\n",
    "\n",
    "\n",
    "def estimate_similarity_amplitude(test_state, train_state, shots, sampler):\n",
    "    qc = build_swap_test_amplitude(test_state, train_state)\n",
    "    out = sampler.run([qc], shots=shots).result()\n",
    "    counts = out[0].data.c.get_counts()\n",
    "    p1 = counts.get(\"1\", 0) / shots\n",
    "    sim = max(0.0, min(1.0, 1 - 2 * p1))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66803c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Core experiment driver (NO PRINTS)\n",
    "# ============================================================\n",
    "\n",
    "def run_qknn_core(\n",
    "    encode_fn_train: Callable[[np.ndarray], Any],\n",
    "    encode_fn_test: Callable[[np.ndarray], Any],\n",
    "    similarity_fn: Callable[[Any, Any, int, SamplerV2], float],\n",
    "    train_size: int,\n",
    "    k_neighbors: int,\n",
    "    shots: int,\n",
    "    prefix: str,\n",
    "):\n",
    "    X, y = load_and_normalize_iris()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        train_size=train_size,\n",
    "        stratify=y,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    num_features = X_train.shape[1]\n",
    "    num_train = len(X_train)\n",
    "    num_test = len(X_test)\n",
    "\n",
    "    sampler = SamplerV2()\n",
    "\n",
    "    # Encode train set once\n",
    "    train_enc_start = time.perf_counter()\n",
    "    train_repr = [encode_fn_train(x) for x in X_train]\n",
    "    train_enc_end = time.perf_counter()\n",
    "\n",
    "    encoding_time_list = []\n",
    "    classification_time_list = []\n",
    "    preds = []\n",
    "\n",
    "    # Main loop\n",
    "    for i in range(num_test):\n",
    "        x_test = X_test[i]\n",
    "\n",
    "        # Encode test\n",
    "        t0 = time.perf_counter()\n",
    "        test_repr = encode_fn_test(x_test)\n",
    "        t1 = time.perf_counter()\n",
    "        encoding_time_list.append((t1 - t0) / num_features)\n",
    "\n",
    "        # Classify\n",
    "        t2 = time.perf_counter()\n",
    "        sims = [\n",
    "            similarity_fn(test_repr, train_repr[j], shots, sampler)\n",
    "            for j in range(num_train)\n",
    "        ]\n",
    "\n",
    "        sims = np.array(sims)\n",
    "        topk = sims.argsort()[::-1][:k_neighbors]\n",
    "        lbls = [y_train[j] for j in topk]\n",
    "        preds.append(mode(lbls))\n",
    "        t3 = time.perf_counter()\n",
    "\n",
    "        classification_time_list.append(t3 - t2)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    cm_df = pd.DataFrame(cm)\n",
    "\n",
    "    # Save results\n",
    "    cm_df.to_csv(f\"{prefix}_confusion_matrix.csv\", index=False)\n",
    "    pd.DataFrame({\"encoding_time\": encoding_time_list}).to_csv(\n",
    "        f\"{prefix}_encoding_times.csv\", index=False\n",
    "    )\n",
    "    pd.DataFrame({\"classification_time\": classification_time_list}).to_csv(\n",
    "        f\"{prefix}_classification_times.csv\", index=False\n",
    "    )\n",
    "    # Training encode summary\n",
    "    pd.DataFrame({\n",
    "        \"total_train_encoding_time\": [train_enc_end - train_enc_start],\n",
    "        \"per_train_sample\": [(train_enc_end - train_enc_start) / num_train],\n",
    "        \"per_train_feature\": [(train_enc_end - train_enc_start) / (num_train * num_features)],\n",
    "    }).to_csv(f\"{prefix}_train_encoding_summary.csv\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Public wrappers\n",
    "# ============================================================\n",
    "\n",
    "def run_angle(\n",
    "    train_size=100,\n",
    "    k_neighbors=10,\n",
    "    shots=2048,\n",
    "    prefix=\"qknn_angle\",\n",
    "):\n",
    "    run_qknn_core(\n",
    "        encode_fn_train=encode_features_to_angles,\n",
    "        encode_fn_test=encode_features_to_angles,\n",
    "        similarity_fn=estimate_similarity_angle,\n",
    "        train_size=train_size,\n",
    "        k_neighbors=k_neighbors,\n",
    "        shots=shots,\n",
    "        prefix=prefix,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_amplitude(\n",
    "    train_size=100,\n",
    "    k_neighbors=10,\n",
    "    shots=2048,\n",
    "    prefix=\"qknn_amplitude\",\n",
    "):\n",
    "    run_qknn_core(\n",
    "        encode_fn_train=encode_features_to_amplitude_state,\n",
    "        encode_fn_test=encode_features_to_amplitude_state,\n",
    "        similarity_fn=estimate_similarity_amplitude,\n",
    "        train_size=train_size,\n",
    "        k_neighbors=k_neighbors,\n",
    "        shots=shots,\n",
    "        prefix=prefix,\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Script entry\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_angle()\n",
    "    run_amplitude()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
